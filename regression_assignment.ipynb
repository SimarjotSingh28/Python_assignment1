{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ec8491-7915-4271-9010-abc1b5193c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.What is Simple Linear Regression?\n",
    "#Simple linear regression is a model that describes the relationship between one dependent and one independent variable using a straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58086ac7-ed00-43ad-adf4-55bf832eb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.What are the key assumptions of Simple Linear Regression?\n",
    "#The two variables need to be using a continuous scale.\n",
    "#The two variables of interest should have a linear relationship, which you can check with a scatterplot.\n",
    "#There should be no spurious outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d6ad88-6513-4145-8a19-22fbe3f546bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. What does the coefficient m represent in the equation Y=mX+c?\n",
    "#the m in this equation represents the slope of the line. it represents the relation between y and x. it is denoted by y-y1/x-x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05669ba6-4219-4e1c-9447-4fb1c256fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.What does the intercept c represent in the equation Y=mX+c?\n",
    "#the c in this equation represent the point on yaxis at which this equation line intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b7faf5-3102-4337-b6fa-b6d33250a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.How do we calculate the slope m in Simple Linear Regression?\n",
    "#it is calculated by y-y1/x-x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b06e1136-543e-41d8-8b76-4579af66620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.What is the purpose of the least squares method in Simple Linear Regression?\n",
    "#Least squares regression is used to predict the behavior of dependent variables. The least squares method provides the overall rationale for the placement of the line of best fit among the data points being studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f4c546-2eab-495e-9020-db17e64ec128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
    "#You can interpret the coefficient of determination (R²) as the proportion of variance in the dependent variable that is predicted by the statistical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec6e03b6-2215-44ad-b838-081d3e2cf5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. What is Multiple Linear Regression?\n",
    "#multiple linear regression is a model that describes the relationship between one dependent and many independent variable using a straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd5eae1d-6b6b-43b3-89d4-e2aa28ea1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. What is the main difference between Simple and Multiple Linear Regression?\n",
    "#The main difference between simple linear regression and multiple linear regression is the number of independent variables used in the model. In simple linear regression, we use one independent variable, while in multiple linear regression, we use two or more independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5e661f5-95b9-4688-9e78-b882c54feae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. What are the key assumptions of Multiple Linear Regression?\n",
    "#Linear Relationship\n",
    "#No Multicollinearity\n",
    "#Variance Inflation Factor (VIF)\n",
    "#Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42923cef-6c1e-465d-a651-345e062968d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression mode?\n",
    "#Heteroskedasticity is usually defined as some variation of the phrase “non-constant error variance”, or the idea that, once the predictors have been included in the regression model.\n",
    "#Heteroskedasticity causes the estimated variances of the regression coefficients to be biased, leading to unreliable hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e4c5ef-0e39-45c6-9530-35855cc0eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "#To fix multicollinearity, one can remove one of the highly correlated variables, combine them into a single variable, or use a dimensionality reduction technique such as principal component analysis to reduce the number of variables while retaining most of the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4229e6fd-4ed2-49e0-8516-52dc28621eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. What are some common techniques for transforming categorical variables for use in regression models?\n",
    "#One-Hot Encoding\n",
    "#Dummy Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "670f4b13-03f6-4d96-bb4f-41ecfb6522be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.What is the role of interaction terms in Multiple Linear Regression?\n",
    "#When there is an interaction term, the effect of one variable that forms the interaction depends on the level of the other variable in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc84444b-a77e-43ae-ad19-625d8e541d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "# It is interpreted the same as a simple linear regression formula—except there are multiple variables that all impact the slope of the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3f72f6c-8ad3-40d7-8aea-b10b6e13af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16.What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "#The slope of regression in species-area relationship predicts species richness of an area. It indicates the dependency of species richness on the area as higher slope reflects higher dependency of the area. Taking into account of a large area, such as country, the slope is almost linear with the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4affb25d-3a29-4e18-8184-0c2463179a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17.How does the intercept in a regression model provide context for the relationship between variables?\n",
    "#The intercept or constant in the regression model represents the mean value of the response variable when all the predictor variables in the model are equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b63d8882-7784-4af4-a099-3a23e026b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18.What are the limitations of using R² as a sole measure of model performance?\n",
    "#it doesn't tell you whether your chosen model is good or bad, nor will it tell you whether the data and predictions are biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58f78d71-f36a-4025-8128-363ad5c388b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19. How would you interpret a large standard error for a regression coefficient?\n",
    "# larger standard error mean lower significance then it means more variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d22a25e5-1a07-4eeb-b0ee-8f8b19e3394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20.How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "#if there appears to be a fan or cone shape in the residual plot, it indicates the presence of heteroskedasticity. Also, regressions with heteroskedasticity show a pattern where the variance of the residuals increases along with the fitted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17a8ad3d-4234-4307-a8a3-333e1e9bdee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22. Why is it important to scale variables in Multiple Linear Regression?\n",
    "#in multiple linear  regression, it is often recommended to scale the features so that the predictors have a mean of 0. This makes it easier to interpret the intercept term as the expected value of Y when the predictor values are set to their means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c3292bd-fc63-4f35-ba9b-6e985594da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23. What is polynomial regression?\n",
    "#Polynomial Regression can handle more complex patterns.it states the relation between x and y in a curve line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41e04879-7070-490c-a4d6-87a1a84ed213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24. How does polynomial regression differ from linear regression?\n",
    "#While Linear Regression captures linear relationships, Polynomial Regression can handle more complex patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60669ae9-7fc7-43f9-9cef-1794d8daf64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25. When is polynomial regression used?\n",
    "#Polynomial regression is needed when there is no linear correlation fitting all the variables. and the relation is shown is curved line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a29a2c9-a5d1-4dff-85fe-07b70010f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#26.What is the general equation for polynomial regression?\n",
    "#the general equation depends on the degree of the regression.it is same as linear regression model \n",
    "#y=c0+c1x1+c2x2....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f5ac358-9262-4e8b-801e-9dcdda34b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#27. Can polynomial regression be applied to multiple variables?\n",
    "#this depends on the degree of the polynomial curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4d18118-bd1e-461a-91f5-4f52e0b8e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#28.What are the limitations of polynomial regression?\n",
    "#limitation is that the higher degree leads to overfit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98d626db-f459-477f-ae07-cc77f4f08fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#29.What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "#The solution is to have a separate validation set on which we can evaluate the model for each polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22d0ebc6-8f61-4925-9682-f8d3251bf0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30. Why is visualization important in polynomial regression?\n",
    "#it is important because the coder will make sure by the visualizing that it is a polynomial regression and then after he can choose the train test model to evaluate the particular regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6297213-ed41-43d5-a5f0-14af338901a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#31. How is polynomial regression implemented in Python?\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#after all the methods like train,test,split,then predict\n",
    "#we will then plot a graph to visualize whether it is polynmial regression or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
